{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = ['kant1.txt', 'kant2.txt', 'kant3.txt']\n",
    "kant_1 = []\n",
    "kant_2 = []\n",
    "kant_3 = []\n",
    "\n",
    "with open(filenames[0], 'r', encoding='utf-8') as file:\n",
    "    critique_of_pure_reason = file.read()[8057:] \n",
    "    kant_1.append(critique_of_pure_reason)\n",
    "\n",
    "\n",
    "with open(filenames[1], 'r', encoding='utf-8') as file:\n",
    "    critique_of_practical_reason = file.read()[1062:] \n",
    "    kant_2.append(critique_of_practical_reason)\n",
    "\n",
    "with open(filenames[2], 'r', encoding='utf-8') as file:\n",
    "    critique_of_judgment = file.read()[70570:] \n",
    "    kant_3.append(critique_of_judgment)\n",
    "\n",
    "kants_works = kant_1[0] + kant_2[0] + kant_3[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/robertbecker/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "custom_stop_words = ['cannot', 'must', 'one', 'also', 'thus', 'would', 'may', 'therefore', 'without', 'even', 'according', 'accordingly']\n",
    "stop_words = set(stopwords.words('english')).union(custom_stop_words)\n",
    "\n",
    "def preprocess(text):\n",
    "    raw = text.lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "    stopped_tokens = [i for i in tokens if not i in stop_words]\n",
    "    return stopped_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lda_model(texts, num_topics=3, passes=15):\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    lda_model = LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=passes)\n",
    "    return lda_model, dictionary, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topics for Work 1:\n",
      "(0, '0.000*\"reason\" + 0.000*\"experience\" + 0.000*\"understanding\" + 0.000*\"existence\" + 0.000*\"us\" + 0.000*\"priori\" + 0.000*\"object\" + 0.000*\"possible\" + 0.000*\"unity\" + 0.000*\"conceptions\"')\n",
      "(1, '0.000*\"reason\" + 0.000*\"experience\" + 0.000*\"conception\" + 0.000*\"understanding\" + 0.000*\"object\" + 0.000*\"possible\" + 0.000*\"time\" + 0.000*\"conceptions\" + 0.000*\"empirical\" + 0.000*\"objects\"')\n",
      "(2, '0.013*\"reason\" + 0.010*\"conception\" + 0.009*\"experience\" + 0.008*\"time\" + 0.008*\"pure\" + 0.008*\"object\" + 0.008*\"conceptions\" + 0.007*\"understanding\" + 0.007*\"intuition\" + 0.006*\"possible\"')\n",
      "\n",
      "\n",
      "Topics for Work 2:\n",
      "(0, '0.001*\"reason\" + 0.000*\"practical\" + 0.000*\"moral\" + 0.000*\"law\" + 0.000*\"pure\" + 0.000*\"principle\" + 0.000*\"freedom\" + 0.000*\"nature\" + 0.000*\"world\" + 0.000*\"object\"')\n",
      "(1, '0.002*\"reason\" + 0.001*\"law\" + 0.001*\"practical\" + 0.001*\"moral\" + 0.001*\"pure\" + 0.001*\"freedom\" + 0.001*\"nature\" + 0.001*\"principle\" + 0.001*\"world\" + 0.001*\"object\"')\n",
      "(2, '0.020*\"reason\" + 0.017*\"law\" + 0.016*\"practical\" + 0.011*\"moral\" + 0.010*\"pure\" + 0.008*\"principle\" + 0.006*\"object\" + 0.005*\"world\" + 0.005*\"principles\" + 0.005*\"freedom\"')\n",
      "\n",
      "\n",
      "Topics for Work 3:\n",
      "(0, '0.000*\"nature\" + 0.000*\"judgement\" + 0.000*\"concept\" + 0.000*\"purpose\" + 0.000*\"object\" + 0.000*\"taste\" + 0.000*\"principle\" + 0.000*\"reason\" + 0.000*\"understanding\" + 0.000*\"faculty\"')\n",
      "(1, '0.000*\"nature\" + 0.000*\"judgement\" + 0.000*\"object\" + 0.000*\"concept\" + 0.000*\"natural\" + 0.000*\"reason\" + 0.000*\"purpose\" + 0.000*\"merely\" + 0.000*\"principle\" + 0.000*\"_\"')\n",
      "(2, '0.015*\"nature\" + 0.012*\"judgement\" + 0.009*\"concept\" + 0.007*\"object\" + 0.007*\"reason\" + 0.007*\"purpose\" + 0.005*\"principle\" + 0.005*\"taste\" + 0.005*\"_\" + 0.005*\"natural\"')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts_1 = [preprocess(kant_1[0])]\n",
    "texts_2 = [preprocess(kant_2[0])]\n",
    "texts_3 = [preprocess(kant_3[0])]\n",
    "\n",
    "lda_model_1, dictionary_1, corpus_1 = create_lda_model(texts_1)\n",
    "lda_model_2, dictionary_2, corpus_2 = create_lda_model(texts_2)\n",
    "lda_model_3, dictionary_3, corpus_3 = create_lda_model(texts_3)\n",
    "\n",
    "for i, model in enumerate([lda_model_1, lda_model_2, lda_model_3], start=1):\n",
    "    print(f\"Topics for Work {i}:\")\n",
    "    topics = model.print_topics(num_words=10)\n",
    "    for topic in topics:\n",
    "        print(topic)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
